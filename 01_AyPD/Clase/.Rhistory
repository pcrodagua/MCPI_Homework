data_glm <- data.frame(heart_data[c(1, 6)])
print(str(data_glm))
model_glm <- lm(fbs~ age, data = data_glm)
# Supuesto de Linealidad
par(mfrow = c(1,2))
plot(data_glm$age, data_glm$fbs, cex.axis=.7, cex.lab=.7, col=4)
abline(model_glm,col=4)
legend("bottomright",
legend = paste(
"R-Cuadrado Ajustado=",
round(summary(model_glm)$adj.r.squared,2)),
cex=.7)
title(main="Sí cumple Supuesto de Linealidad R cuadrado Ajustado es mayor a 0.7",
cex.main=.7,col.main=4)
data_glm <- data.frame(heart_data[c(1, 5)])
print(str(data_glm))
model_glm <- lm(chol~ age, data = data_glm)
# Supuesto de Linealidad
par(mfrow = c(1,2))
plot(data_glm$age, data_glm$chol, cex.axis=.7, cex.lab=.7, col=4)
abline(model_glm,col=4)
legend("bottomright",
legend = paste(
"R-Cuadrado Ajustado=",
round(summary(model_glm)$adj.r.squared,2)),
cex=.7)
title(main="Sí cumple Supuesto de Linealidad R cuadrado Ajustado es mayor a 0.7",
cex.main=.7,col.main=4)
data_glm <- data.frame(heart_data[c(3, 8)])
print(str(data_glm))
model_glm <- lm(cp~ thalach, data = data_glm)
# Supuesto de Linealidad
par(mfrow = c(1,2))
plot(data_glm$cp, data_glm$thalach, cex.axis=.7, cex.lab=.7, col=4)
abline(model_glm,col=4)
legend("bottomright",
legend = paste(
"R-Cuadrado Ajustado=",
round(summary(model_glm)$adj.r.squared,2)),
cex=.7)
title(main="Sí cumple Supuesto de Linealidad R cuadrado Ajustado es mayor a 0.7",
cex.main=.7,col.main=4)
data_glm <- data.frame(heart_data[c(5, 8)])
print(str(data_glm))
model_glm <- lm(chol~ thalach, data = data_glm)
# Supuesto de Linealidad
par(mfrow = c(1,2))
plot(data_glm$chol, data_glm$thalach, cex.axis=.7, cex.lab=.7, col=4)
abline(model_glm,col=4)
legend("bottomright",
legend = paste(
"R-Cuadrado Ajustado=",
round(summary(model_glm)$adj.r.squared,2)),
cex=.7)
title(main="Sí cumple Supuesto de Linealidad R cuadrado Ajustado es mayor a 0.7",
cex.main=.7,col.main=4)
kable(head(data), caption = 'Final del Conjunto de Datos')
kable(head(data), caption = 'Principio del Conjunto de Datos')
dataset = read.csv(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/compentencia/cancer.csv', stringsAsFactors = FALSE)
str(dataset)
# DATA PREPROCESSING
dataset$Diagnosis <- lapply(dataset$Diagnosis, as.character)
dataset$Diagnosis[dataset$Diagnosis == 'M'] <- 1
dataset$Diagnosis[dataset$Diagnosis == 'B'] <- 0
dataset$Diagnosis <- as.numeric(dataset$Diagnosis)
dataset <- dataset[!is.na(dataset$Diagnosis),]
dataset <- dataset[2:length(dataset)]
# ENCODE AS factor(
dataset$Diagnosis <- factor(dataset$Diagnosis, levels = c(0,1))
# DATA SPLITTING
library(caTools)
set.seed(123)
split = sample.split(dataset$Diagnosis, SplitRatio = 0.70)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# FEATURE SCALING
# PROCESSING
library(e1071)
classifier = svm(formula = Diagnosis ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set)
y_pred
# confussion matrix
cm = table(test_set[, 1], y_pred)
cm
fitted.results <- ifelse(y_pred > 0.5, 1, 0)
miss.classified.error <- mean(y_pred != test_set$Diagnosis)
print(paste('Acurracy', 1 - miss.classified.error))
cm
str(dataset)
dataset = read.csv(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/compentencia/cancer.csv', stringsAsFactors = FALSE)
str(dataset)
# DATA PREPROCESSING
dataset$Diagnosis <- lapply(dataset$Diagnosis, as.character)
dataset$Diagnosis[dataset$Diagnosis == 'M'] <- 1
dataset$Diagnosis[dataset$Diagnosis == 'B'] <- 0
dataset$Diagnosis <- as.numeric(dataset$Diagnosis)
dataset <- dataset[!is.na(dataset$Diagnosis),]
dataset <- dataset[2:length(dataset)]
# ENCODE AS factor(
dataset$Diagnosis <- factor(dataset$Diagnosis, levels = c(0,1))
# DATA SPLITTING
library(caTools)
set.seed(123)
split = sample.split(dataset$Diagnosis, SplitRatio = 0.70)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# FEATURE SCALING
# PROCESSING
library(e1071)
classifier = svm(formula = Diagnosis ~ concavity + concave.points + area + smoothness,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set)
y_pred
# confussion matrix
cm = table(test_set[, 1], y_pred)
cm
fitted.results <- ifelse(y_pred > 0.5, 1, 0)
miss.classified.error <- mean(y_pred != test_set$Diagnosis)
print(paste('Acurracy', 1 - miss.classified.error))
library(e1071)
datos <- read.delim(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/caballos.txt')
library(e1071)
datos <- read.delim(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/caballos.txt')
library(e1071) # SVM
View(datos)
class(datos$Height)
class(datos$Weight)
class(datos$animal)
plot(datos[,-3], col=1.5, pch=19)
plot(datos[,-3], col=c('red', 'blue'), pch=19)
model_svm <- svm(animal ~., data=datos, type='c-classification', kernel='linear', scale = FALSE)
model_svm <- svm(animal ~., data=datos, type='c-classification', kernel='linear')
model_svm <- svm(animal ~., data=datos,
type = 'C-classification',
kernel = 'linear')
summary(model_svm)
# plot
points(datos[model_svm$index, c(1, 2)], col='red', cex=2, lwd=1.5)
B <- -model_svm$rho
# parametes of the hyperplane
w <- t(model_svm$coefs)%*%model_svm$SV
b <- -model_svm$rho
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='green', lty=3)
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
w
b
model_svm <- svm(animal ~., data=datos,
type = 'C-classification',
kernel = 'linear',
scale = FALSE)
summary(model_svm)
# plot
points(datos[model_svm$index, c(1, 2)], col='red', cex=2, lwd=1.5)
# parametes of the hyperplane
w <- t(model_svm$coefs)%*%model_svm$SV
b <- -model_svm$rho
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
clase <- as.numeric(as.character(datos$animal))
# old
plot(datos[, -3], col=(clase + 3)/2, pch=19, xlim=(0, 250), ylim=(0,250))
# old
plot(datos[, -3], col=(clase + 3)/2, pch=19, xlim=c(0, 250), ylim=c(0,250))
# graficando los datos nuevo y viejos
# sobreponer datos nuevos sobre los viejos
points(nuevos[1, ] col='green', pch=19)
# graficando los datos nuevo y viejos
# sobreponer datos nuevos sobre los viejos
points(nuevos[1, ], col='green', pch=19)
# NEW
nuevos <- data.frame(
Height=c(67, 121, 100),
Weight=c(121, 190, 100))
clase <- as.numeric(as.character(datos$animal))
# old
plot(datos[, -3], col=(clase + 3)/2, pch=19, xlim=c(0, 250), ylim=c(0,250))
# graficando los datos nuevo y viejos
# sobreponer datos nuevos sobre los viejos
points(nuevos[1, ], col='green', pch=19)
points(nuevos[2, ], col='blue', pch=19)
points(nuevos[3, ], col='pink', pch=19)
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
predict(model_svm, nuevos)
## roc
library(plotROC)
devtools::install_github("sachsmc/plotROC")
install_github("sachsmc/plotROC")
## roc
library(pROC)
dataset = read.csv(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/compentencia/cancer.csv', stringsAsFactors = FALSE)
str(dataset)
# DATA PREPROCESSING
dataset$Diagnosis <- lapply(dataset$Diagnosis, as.character)
dataset$Diagnosis[dataset$Diagnosis == 'M'] <- 1
dataset$Diagnosis[dataset$Diagnosis == 'B'] <- 0
dataset$Diagnosis <- as.numeric(dataset$Diagnosis)
dataset <- dataset[!is.na(dataset$Diagnosis),]
dataset <- dataset[2:length(dataset)]
# ENCODE AS factor(
dataset$Diagnosis <- factor(dataset$Diagnosis, levels = c(0,1))
# DATA SPLITTING
library(caTools)
set.seed(123)
split = sample.split(dataset$Diagnosis, SplitRatio = 0.70)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# FEATURE SCALING
# PROCESSING
library(e1071)
classifier = svm(formula = Diagnosis ~ concavity + concave.points + area + smoothness,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set)
y_pred
# confussion matrix
cm = table(test_set[, 1], y_pred)
cm
fitted.results <- ifelse(y_pred > 0.5, 1, 0)
miss.classified.error <- mean(y_pred != test_set$Diagnosis)
print(paste('Acurracy', 1 - miss.classified.error))
## roc
library(pROC)
auc_ <- auc(test_set$Diagnosis, y_pred)
roc(y_pred, classifier$fitted.values, plot=TRUE)
roc(y_pred, classifier$fitted, plot=TRUE)
roc(y_pred, fitted.results, plot=TRUE)
roc(test_set$Diagnosis, fitted.results, plot=TRUE)
roc(test_set$Diagnosis, y_pred, plot=TRUE)
auc_ <- auc(test_set$Diagnosis, y_pred[ ,2])
y_pred
y_pred[, 2]
auc_ <- auc(test_set$Diagnosis, y_pred[, 1])
y_pred[, 1]
auc_ <- auc(test_set$Diagnosis, type(y_pred))
type(y_pred)
typeof(y_pred)
auc_ <- auc(test_set$Diagnosis, typeof(y_pred[c(1)]))
typeof(y_pred[c(1)])
y_pred[c(1)]
auc_ <- auc(test_set$Diagnosis, y_pred[,2])
auc_ <- auc(test_set$Diagnosis, unlist(y_pred))
auc?
l
?auc
?roc
roc_ roc(response = fitted.results, predictor = y_pred)
roc_ <- roc(response = fitted.results, predictor = y_pred)
## roc
library(ROCR)
# roc_ <- roc(response = fitted.results, predictor = y_pred)
roc.perf = performance(y_pred, measure = "tpr", x.measure = "fpr")
dataset = read.csv(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/compentencia/cancer.csv', stringsAsFactors = FALSE)
str(dataset)
# DATA PREPROCESSING
dataset$Diagnosis <- lapply(dataset$Diagnosis, as.character)
dataset$Diagnosis[dataset$Diagnosis == 'M'] <- 1
dataset$Diagnosis[dataset$Diagnosis == 'B'] <- 0
dataset$Diagnosis <- as.numeric(dataset$Diagnosis)
dataset <- dataset[!is.na(dataset$Diagnosis),]
dataset <- dataset[2:length(dataset)]
# ENCODE AS factor(
dataset$Diagnosis <- factor(dataset$Diagnosis, levels = c(0,1))
# DATA SPLITTING
library(caTools)
set.seed(123)
split = sample.split(dataset$Diagnosis, SplitRatio = 0.70)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# FEATURE SCALING
# PROCESSING
library(e1071)
classifier = svm(formula = Diagnosis ~ concavity + concave.points + area + smoothness,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set)
y_pred
# confussion matrix
cm = table(test_set[, 1], y_pred)
cm
fitted.results <- ifelse(y_pred > 0.5, 1, 0)
miss.classified.error <- mean(y_pred != test_set$Diagnosis)
print(paste('Acurracy', 1 - miss.classified.error))
dataset = read.csv(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/compentencia/cancer.csv', stringsAsFactors = FALSE)
str(dataset)
# DATA PREPROCESSING
dataset$Diagnosis <- lapply(dataset$Diagnosis, as.character)
dataset$Diagnosis[dataset$Diagnosis == 'M'] <- 1
dataset$Diagnosis[dataset$Diagnosis == 'B'] <- 0
dataset$Diagnosis <- as.numeric(dataset$Diagnosis)
dataset <- dataset[!is.na(dataset$Diagnosis),]
dataset <- dataset[2:length(dataset)]
# ENCODE AS factor(
dataset$Diagnosis <- factor(dataset$Diagnosis, levels = c(0,1))
# DATA SPLITTING
library(caTools)
set.seed(123)
split = sample.split(dataset$Diagnosis, SplitRatio = 0.70)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# FEATURE SCALING
# PROCESSING
library(e1071)
classifier = svm(formula = Diagnosis ~ ., # concavity + concave.points + area + smoothness,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set)
y_pred
# confussion matrix
cm = table(test_set[, 1], y_pred)
cm
fitted.results <- ifelse(y_pred > 0.5, 1, 0)
miss.classified.error <- mean(y_pred != test_set$Diagnosis)
print(paste('Acurracy', 1 - miss.classified.error))
datos <- read.delim(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/caballos.txt')
library(e1071) # SVM
class(datos$Height)
class(datos$Weight)
class(datos$animal)
datos$animal <- as.character(as.factor(datos$animal))
plot(datos[,-3], col=1.5, pch=19)
model_svm <- svm(animal ~., data=datos,
type = 'C-classification',
kernel = 'linear',
scale = FALSE)
summary(model_svm)
# plot
points(datos[model_svm$index, c(1, 2)], col='red', cex=2, lwd=1.5)
# parametes of the hyperplane
w <- t(model_svm$coefs)%*%model_svm$SV
b <- -model_svm$rho
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
# NEW
nuevos <- data.frame(
Height=c(67, 121, 100),
Weight=c(121, 190, 100))
clase <- as.numeric(as.character(datos$animal))
# old
plot(datos[, -3], col=(clase + 3)/2, pch=19, xlim=c(0, 250), ylim=c(0,250))
# graficando los datos nuevo y viejos
# sobreponer datos nuevos sobre los viejos
points(nuevos[1, ], col='green', pch=19)
points(nuevos[2, ], col='blue', pch=19)
points(nuevos[3, ], col='pink', pch=19)
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
pdf('grafica.pdf')
dev.off()
predict(model_svm, nuevos)
setwd("~/Proyects/MCPI_Homework/01_AyPD/Clase")
datos <- read.delim(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/caballos.txt')
library(e1071) # SVM
class(datos$Height)
class(datos$Weight)
class(datos$animal)
datos$animal <- as.character(as.factor(datos$animal))
plot(datos[,-3], col=1.5, pch=19)
model_svm <- svm(animal ~., data=datos,
type = 'C-classification',
kernel = 'linear',
scale = FALSE)
summary(model_svm)
# plot
points(datos[model_svm$index, c(1, 2)], col='red', cex=2, lwd=1.5)
# parametes of the hyperplane
w <- t(model_svm$coefs)%*%model_svm$SV
b <- -model_svm$rho
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
# NEW
nuevos <- data.frame(
Height=c(67, 121, 100),
Weight=c(121, 190, 100))
clase <- as.numeric(as.character(datos$animal))
# old
plot(datos[, -3], col=(clase + 3)/2, pch=19, xlim=c(0, 250), ylim=c(0,250))
# graficando los datos nuevo y viejos
# sobreponer datos nuevos sobre los viejos
points(nuevos[1, ], col='green', pch=19)
points(nuevos[2, ], col='blue', pch=19)
points(nuevos[3, ], col='pink', pch=19)
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
pdf('grafica.pdf')
dev.off()
predict(model_svm, nuevos)
datos <- read.delim(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/caballos.txt')
library(e1071) # SVM
class(datos$Height)
class(datos$Weight)
class(datos$animal)
datos$animal <- as.character(as.factor(datos$animal))
plot(datos[,-3], col=1.5, pch=19)
model_svm <- svm(animal ~., data=datos,
type = 'C-classification',
kernel = 'linear',
scale = FALSE)
summary(model_svm)
# plot
points(datos[model_svm$index, c(1, 2)], col='red', cex=2, lwd=1.5)
# parametes of the hyperplane
w <- t(model_svm$coefs)%*%model_svm$SV
b <- -model_svm$rho
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
# NEW
nuevos <- data.frame(
Height=c(67, 121, 100),
Weight=c(121, 190, 100))
clase <- as.numeric(as.character(datos$animal))
# old
pdf('grafica.pdf')
plot(datos[, -3], col=(clase + 3)/2, pch=19, xlim=c(0, 250), ylim=c(0,250))
# graficando los datos nuevo y viejos
# sobreponer datos nuevos sobre los viejos
points(nuevos[1, ], col='green', pch=19)
points(nuevos[2, ], col='blue', pch=19)
points(nuevos[3, ], col='pink', pch=19)
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
dev.off()
predict(model_svm, nuevos)
datos <- read.delim(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/caballos.txt')
library(e1071) # SVM
class(datos$Height)
class(datos$Weight)
class(datos$animal)
datos$animal <- as.character(as.factor(datos$animal))
plot(datos[,-3], col=1.5, pch=19)
model_svm <- svm(animal ~., data=datos,
type = 'C-classification',
kernel = 'linear',
scale = FALSE)
summary(model_svm)
# plot
points(datos[model_svm$index, c(1, 2)], col='red', cex=2, lwd=1.5)
# parametes of the hyperplane
w <- t(model_svm$coefs)%*%model_svm$SV
b <- -model_svm$rho
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
# NEW
nuevos <- data.frame(
Height=c(67, 121, 100),
Weight=c(121, 190, 100))
clase <- as.numeric(as.character(datos$animal))
# old
pdf('grafica.png')
plot(datos[, -3], col=(clase + 3)/2, pch=19, xlim=c(0, 250), ylim=c(0,250))
# graficando los datos nuevo y viejos
# sobreponer datos nuevos sobre los viejos
points(nuevos[1, ], col='green', pch=19)
points(nuevos[2, ], col='blue', pch=19)
points(nuevos[3, ], col='pink', pch=19)
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
dev.off()
predict(model_svm, nuevos)
datos <- read.delim(file = 'Proyects/MCPI_Homework/01_AyPD/Clase/caballos.txt')
library(e1071) # SVM
class(datos$Height)
class(datos$Weight)
class(datos$animal)
datos$animal <- as.character(as.factor(datos$animal))
plot(datos[,-3], col=1.5, pch=19)
model_svm <- svm(animal ~., data=datos,
type = 'C-classification',
kernel = 'linear',
scale = FALSE)
summary(model_svm)
# plot
points(datos[model_svm$index, c(1, 2)], col='red', cex=2, lwd=1.5)
# parametes of the hyperplane
w <- t(model_svm$coefs)%*%model_svm$SV
b <- -model_svm$rho
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
# NEW
nuevos <- data.frame(
Height=c(67, 121, 100),
Weight=c(121, 190, 100))
clase <- as.numeric(as.character(datos$animal))
# old
pdf('grafica.tiff')
plot(datos[, -3], col=(clase + 3)/2, pch=19, xlim=c(0, 250), ylim=c(0,250))
# graficando los datos nuevo y viejos
# sobreponer datos nuevos sobre los viejos
points(nuevos[1, ], col='green', pch=19)
points(nuevos[2, ], col='blue', pch=19)
points(nuevos[3, ], col='pink', pch=19)
# hyperplane
abline(a = -b/w[1, 2], b=-w[1, 1]/w[1, 2], col='red', lty=3)
dev.off()
predict(model_svm, nuevos)
